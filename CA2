# MSc Data Analytics CA2
## Data Visualisation and Preparation

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import math

## Data Extraction and Manipulation
df_UN = pd.read_csv("UNDataset.csv")

df_UN.head()

df_UN["City"].unique()

df_UN.sort_values(["City"])

newdf = df_UN.loc[(df_UN["City"] == 'Dublin') | 
                  (df_UN["City"] == 'Porto') | 
                  (df_UN["City"] == 'Glasgow') | 
                  (df_UN["City"] == 'Manchester')| 
                  (df_UN["City"] == 'Edinburgh')| 
                  (df_UN["City"] == 'Copenhagen')|
                 (df_UN["City"] == 'Zurich')]
newdf

newdf["City"].unique()

newdf1 = newdf.loc[(newdf["Type"] == 'Tram')|
                 (newdf["Type"] == 'Metro')]
newdf1

newdf2 = newdf1.loc[(newdf1["Variable"] == 'Pass')]

newdf3 = newdf2.loc[(newdf2["Year"] >= 2018)]

newdf3.shape

df_final=newdf3.drop(columns=['Countrycode','Type', 'Variable', 'Note'])

df_final.head()

df_final= df_final.rename(columns={"Value (Thousands of Passengers)":"Annual No. of Passengers (Thousand)"})
df_final.head()

df_final.shape

df_final.sort_values(["City"])

df_final.shape

df_final2 = pd.read_csv("ManualData.csv")

df_final2.sort_values(["City"])

df_final2

mergedf1 = pd.merge(df_final, df_final2, on = ["City", "Year"])
mergedf1.head()

mergedf1

mergedf1.set_index('Year')

## Exploratory Data Analysis
mergedf1.describe(include=object)
mergedf1.describe()

mergedf1["City"].unique()

duplicate_rows_df = mergedf1[mergedf1.duplicated()] 
print("Number of duplicate rows: ", duplicate_rows_df.shape)

print(mergedf1.isnull().sum())

## use of fillna() to take average of previous four years for each city to fill null value with mean of previous four years. Source: https://stackoverflow.com/questions/58507317/how-to-fillna-impute-by-using-the-mean-of-the-last-3-rows-in-the-same-column

mergedf1.fillna(mergedf1.rolling(4, min_periods=1).mean().shift()) 

## using a boxplot to gain insight into the data 

sns.boxplot(x=mergedf1['Annual No. of Passengers (Thousand)']) 

plt.title("Annual No. of Passengers Across Seven European Cities", fontsize=14)
plt.xlabel("No. of Passengers (Thousand)", fontsize=12)

## plotting data to gain insights into the data set

fig, ax = plt.subplots(figsize=(30, 15))
sns.barplot(mergedf1, x="Year", y="Annual No. of Passengers (Thousand)", hue="City", width=.9)

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-")
plt.legend(fontsize="22", loc ="upper left")

plt.title("Annual Number of Passengers Across Seven European Cities", fontsize=36)
plt.xlabel("Year", fontsize=28)
plt.ylabel("Number of Passengers (Thousand)", fontsize=28)
plt.xticks(fontsize=20) ## https://stackabuse.com/rotate-axis-labels-in-matplotlib/
plt.yticks(fontsize=20)

## plotting data to gain insights into the data set

fig, ax = plt.subplots(figsize=(30, 15))
sns.barplot(mergedf1, x="Year", y="Population (thousand)", hue="City", width=.9)

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-")
plt.legend(fontsize="22", loc ="upper left")

plt.title("Population Across Seven European Cities", fontsize=36)
plt.xlabel("Year", fontsize=28)
plt.ylabel("Number of Passengers (Thousand)", fontsize=28)
plt.xticks(fontsize=20) ## https://stackabuse.com/rotate-axis-labels-in-matplotlib/
plt.yticks(fontsize=20)

## plotting data to gain insights into the data set

fig, ax = plt.subplots(figsize=(30, 15))
sns.barplot(mergedf1, x="Year", y="Congestion (%)", hue="City", width=.9)

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-")
plt.legend(fontsize="22", loc ="upper left")

plt.title("Congestion Across Seven European Cities", fontsize=36)
plt.xlabel("Year", fontsize=28)
plt.ylabel("Number of Passengers (Thousand)", fontsize=28)
plt.xticks(fontsize=20) ## https://stackabuse.com/rotate-axis-labels-in-matplotlib/
plt.yticks(fontsize=20)

sns.scatterplot(data=mergedf1, x="Annual No. of Passengers (Thousand)", y="Congestion (%)", hue="City")

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-")

plt.title("Annual Number of Passengers vs Congestion (%)", fontsize=14)
plt.xlabel("Annual No. of Passengers (Thousand)", fontsize=10)
plt.ylabel("Congestion (%)", fontsize=10)
plt.xticks(fontsize=10) ## https://stackabuse.com/rotate-axis-labels-in-matplotlib/
plt.yticks(fontsize=10)

sns.scatterplot(data=mergedf1, x="Price of One Litre of Diesel (Euro)" , y="Congestion (%)", hue="City")

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-")

plt.title("Price of One Litre of Diesel (Euro) vs Congestion (%)", fontsize=14)
plt.xlabel("Price of One Litre of Diesel (Euro)", fontsize=10)
plt.ylabel("Congestion (%)", fontsize=10)
plt.xticks(fontsize=10) ## https://stackabuse.com/rotate-axis-labels-in-matplotlib/
plt.yticks(fontsize=10)

sns.scatterplot(data=mergedf1, x="Annual No. of Passengers (Thousand)", y="Population (thousand)", hue="City")

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-")

plt.title("Annual No. of Passengers (Thousand) vs Population (thousand)", fontsize=14)
plt.xlabel("Annual No. of Passengers (Thousand)", fontsize=10)
plt.ylabel("Population (thousand)", fontsize=10)
plt.xticks(fontsize=10) ## https://stackabuse.com/rotate-axis-labels-in-matplotlib/
plt.yticks(fontsize=10)

sns.scatterplot(data=mergedf1, x="Congestion (%)", y="Population (thousand)", hue="City")

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-")

plt.title("Congestion (%) vs Population (thousand)", fontsize=14)
plt.xlabel("Congestion (%)", fontsize=10)
plt.ylabel("Population (thousand)", fontsize=10)
plt.xticks(fontsize=10) ## https://stackabuse.com/rotate-axis-labels-in-matplotlib/
plt.yticks(fontsize=10)

mergedf1.corr()

## plotting data to gain insights into the data set

sns.relplot(data=mergedf1, x="Year", y="Annual No. of Passengers (Thousand)", hue="City", kind="line", height=8)

plt.grid(True, color = "grey", linewidth = "1", linestyle = "-") ## Source https://www.geeksforgeeks.org/grids-in-matplotlib/

plt.title("Annual No. of Passengers Across Seven European Cities", fontsize=14)
plt.xlabel("Year", fontsize=12)
plt.ylabel("Annual No. of Passengers (thousand)", fontsize=12)

sns.histplot(data=mergedf1, x="Congestion (%)", kde=True)

sns.histplot(data=mergedf1, x="Price of One Litre of Diesel (Euro)", kde=True)

# Statistical Analysis

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import statistics as stats
import scipy.stats as stats
from statsmodels.stats import weightstats

### Descriptive Statistics
mergedf.describe()

sns.pairplot(mergedf)
plt.grid(True, color = "grey", linewidth = "1", linestyle = "-") ## Source https://www.geeksforgeeks.org/grids-in-matplotlib/
plt.title("Graphs of Various Variables Effecting Congestion in Cities in Europe", fontsize=14)

sns.histplot(data=mergedf, x="Congestion (%)", kde=True)

sns.histplot(data=mergedf, x="Annual No. of Passengers (Thousand)", kde=True)

sns.histplot(data=mergedf, x="Population", kde=True)

plt.title("Histogram Showing Population of Seven European Cities 2018-2022", fontsize=14)

### Inferential Statistics

## Hypothesis Test (Z-Test)
X = mergedf["Annual No. of Passengers (Thousand)"]
passenger_std = X.std()
#### H0: mu = 58071, H1: mu > 58071 : As the mean of the annual number of passengers is 58071 the alternative hypothesis should be greater than 5000.
mu = 58071
z_score, p_value = weightstats.ztest(X, value = mu, ddof=1, alternative = 'larger')
z_score
p_value
As the p-value is greater than alpha, we reject the null hypothesis and accept the alternative hypothesis that mu > 58071. 
Therefore, we have enough evidence at 95% confidence interval to suggest that the average annual number of passengers will be greater than 58,071,000 across the seven cities.
X = mergedf["Congestion"]
congestion_std1 = X.std()
## H0: mu = 29.42, H1: mu > 29.42 : As the mean of the annual number of passengers is 58071 the alternative hypothesis should be greater than 5000.
mu = 29.42
z_score, p_value = weightstats.ztest(X, value = mu, ddof=1, alternative = 'larger')
z_score
p_value
As the p-value is greater than alpha we accept the null hypothesis and reject the alternative hypothesis that mu > 29.42 
Therefore, we have enough evidence at 95% confidence interval to suggest that the average congestion level across the seven cities will be 29.42







## Parametric/Non Parametric Testing
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
import scipy as scipy

mergedf
mergedf = mergedf.rename(columns={"Annual No. of Passengers (Thousand)":"Passengers", "Population (thousand)":"Population", "Congestion (%)":"Congestion"})
mergedf

## Sharpiro Wilk Test- Checking the conditions for ANOVA
#QQ-plot
stats.probplot(mergedf.Passengers, plot = plt)
plt.figure()
## Sharpiro Wil Test to test Normality of Data

## H0: Data comes from normal dist
## H1: Data does NOT come from normal dist

stats.shapiro(mergedf.Passengers[mergedf.City=="Dublin"])
## p_value is greater than alpha therefore null hypothesis should be accepted.
## Evidence suggests that data for Dublin comes from normal distribution
stats.shapiro(mergedf.Passengers[mergedf.City=="Copenhagen"])
stats.shapiro(mergedf.Passengers[mergedf.City=="Porto"])
stats.shapiro(mergedf.Passengers[mergedf.City=="Zurich"])
stats.shapiro(mergedf.Passengers[mergedf.City=="Glasgow"])
stats.shapiro(mergedf.Passengers[mergedf.City=="Edinburgh"])
stats.shapiro(mergedf.Passengers[mergedf.City=="Manchester"])
## As evidenced above by plot and p_value test, data for Zurich is NOT normally distributed

#QQ-plot
stats.probplot(mergedf.Congestion, plot = plt)
plt.figure()

stats.shapiro(mergedf.Congestion[mergedf.City=="Dublin"])
## p_value is greater than alpha therefore null hypothesis should be accepted.
## Evidence suggests that data for Dublin comes from normal distribution
stats.shapiro(mergedf.Congestion[mergedf.City=="Copenhagen"])
stats.shapiro(mergedf.Congestion[mergedf.City=="Porto"])
stats.shapiro(mergedf.Congestion[mergedf.City=="Zurich"])
stats.shapiro(mergedf.Congestion[mergedf.City=="Manchester"])
stats.shapiro(mergedf.Congestion[mergedf.City=="Edinburgh"])
stats.shapiro(mergedf.Congestion[mergedf.City=="Glasgow"])

dublin = mergedf.Congestion[mergedf.City=="Dublin"]
copenhagen = mergedf.Congestion[mergedf.City=="Copenhagen"]
porto = mergedf.Congestion[mergedf.City=="Porto"]
zurich = mergedf.Congestion[mergedf.City=="Zurich"]
manchester = mergedf.Congestion[mergedf.City=="Manchester"]
glasgow = mergedf.Congestion[mergedf.City=="Glasgow"]
edinburgh = mergedf.Congestion[mergedf.City=="Edinburgh"]

## ANOVA (One Way)
## Homogenity of the variances ---> Levene Test
## H0: the variances are equal
## H1: the variances are not equal
from scipy.stats import levene
levene(dublin, copenhagen, porto, zurich, edinburgh, manchester, glasgow, center = 'mean')
## accept null hypothesis as p_value is greater than alpha
## H0: muDublin = muCopenhgen = muZurich = muPorto = muManchester = muGlasgow = muEdinburgh
## H1: there are at least 2 mu which are different

## we analyse congestion based on city
model = ols('Congestion~City', data=mergedf).fit()
aov = sm.stats.anova_lm(model, type=2)
print(aov)
## therefore as PR(>F) value which is our p_value is less than alpha then we reject the null hypothesis.




